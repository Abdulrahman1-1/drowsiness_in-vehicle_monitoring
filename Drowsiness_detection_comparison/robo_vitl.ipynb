{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.transforms import InterpolationMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class for the new structure\n",
    "class DrowsinessCSV_Dataset(Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.transform = transform\n",
    "\n",
    "        # Locate the CSV file\n",
    "        csv_files = [f for f in os.listdir(folder_path) if f.endswith(\"_classes.csv\")]\n",
    "        assert len(csv_files) == 1, \"Expected one _classes.csv file per folder\"\n",
    "        csv_path = os.path.join(folder_path, csv_files[0])\n",
    "\n",
    "        # Load labels\n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            filename = row['filename']\n",
    "            label = int(row['1'])  # if 1 column is 1, class is 1 (drowsy), else 0 (alert)\n",
    "            self.image_paths.append(os.path.join(folder_path, filename))\n",
    "            self.labels.append(label)\n",
    "\n",
    "        print(f\"Loaded {len(self.image_paths)} samples from {folder_path}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained ViT model and feature extractor\n",
    "pretrained_vit_weights = torchvision.models.ViT_L_16_Weights.DEFAULT\n",
    "pretrained_vit = torchvision.models.vit_l_16(weights=pretrained_vit_weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze some layers for fine-tuning\n",
    "for name, parameter in pretrained_vit.named_parameters():\n",
    "    if \"encoder\" in name:  # Fine-tune the encoder layers\n",
    "        parameter.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace classification head for 2-class prediction\n",
    "pretrained_vit.heads = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=1024, out_features=2)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224), interpolation=InterpolationMode.BILINEAR),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224), interpolation=InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9638 samples from ./Drowsiness-/-Fatigue_Detection-4/train\n",
      "Loaded 814 samples from ./Drowsiness-/-Fatigue_Detection-4/valid\n"
     ]
    }
   ],
   "source": [
    "# Dataset root path\n",
    "root_dir = \"./Drowsiness-/-Fatigue_Detection-4\"\n",
    "train_dataset = DrowsinessCSV_Dataset(os.path.join(root_dir, \"train\"), transform=train_transform)\n",
    "val_dataset = DrowsinessCSV_Dataset(os.path.join(root_dir, \"valid\"), transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=8, pin_memory=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = optim.AdamW([\n",
    "    {'params': pretrained_vit.heads.parameters(), 'lr': 1e-3},\n",
    "    {'params': [param for name, param in pretrained_vit.named_parameters() if \"encoder\" in name], 'lr': 1e-4}\n",
    "], weight_decay=1e-4)\n",
    "\n",
    "# Scheduler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 0.3954, Accuracy: 0.8077\n",
      "Validation Accuracy: 0.9459\n",
      "New best model saved.\n",
      "Epoch [2/25], Loss: 0.2738, Accuracy: 0.8842\n",
      "Validation Accuracy: 0.9631\n",
      "New best model saved.\n",
      "Epoch [3/25], Loss: 0.2517, Accuracy: 0.8941\n",
      "Validation Accuracy: 0.9607\n",
      "Epoch [4/25], Loss: 0.2368, Accuracy: 0.8996\n",
      "Validation Accuracy: 0.9472\n",
      "Epoch [5/25], Loss: 0.2090, Accuracy: 0.9156\n",
      "Validation Accuracy: 0.9607\n",
      "Epoch 00005: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00005: reducing learning rate of group 1 to 5.0000e-05.\n",
      "Epoch [6/25], Loss: 0.1513, Accuracy: 0.9370\n",
      "Validation Accuracy: 0.9386\n",
      "Epoch [7/25], Loss: 0.1287, Accuracy: 0.9475\n",
      "Validation Accuracy: 0.9423\n",
      "Early stopping triggered. Training stopped.\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 25\n",
    "best_val_accuracy = 0.0\n",
    "epochs_no_improve = 0\n",
    "early_stopping_patience = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    pretrained_vit.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        inputs, labels = batch\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = pretrained_vit(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels).item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataloader)\n",
    "    epoch_accuracy = correct_predictions / total_predictions\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    pretrained_vit.eval()\n",
    "    val_correct_predictions = 0\n",
    "    val_total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = pretrained_vit(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            val_correct_predictions += torch.sum(preds == labels).item()\n",
    "            val_total_predictions += labels.size(0)\n",
    "\n",
    "    val_accuracy = val_correct_predictions / val_total_predictions\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    scheduler.step(val_accuracy)\n",
    "\n",
    "    # Early stopping\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(pretrained_vit.state_dict(), 'best_vitl_drowsy2class.pth')\n",
    "        print(\"New best model saved.\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= early_stopping_patience:\n",
    "        print(\"Early stopping triggered. Training stopped.\")\n",
    "        break\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (conv_proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): Sequential(\n",
       "      (encoder_layer_0): EncoderBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_1): EncoderBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_2): EncoderBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_3): EncoderBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_4): EncoderBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_5): EncoderBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_6): EncoderBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_7): EncoderBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_8): EncoderBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_9): EncoderBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_10): EncoderBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_11): EncoderBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_12): EncoderBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_13): EncoderBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_14): EncoderBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_15): EncoderBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_16): EncoderBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_17): EncoderBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_18): EncoderBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_19): EncoderBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_20): EncoderBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_21): EncoderBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_22): EncoderBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_23): EncoderBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (heads): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the best model\n",
    "pretrained_vit.load_state_dict(torch.load('best_vitl_drowsy2class.pth'))\n",
    "pretrained_vit.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 482 samples from ./Drowsiness-/-Fatigue_Detection-4/test\n"
     ]
    }
   ],
   "source": [
    "# Prepare test dataset and dataloader\n",
    "test_dataset = DrowsinessCSV_Dataset(os.path.join(root_dir, \"test\"), transform=val_transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing phase\n",
    "all_labels, all_preds = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = pretrained_vit(inputs)\n",
    "        all_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9730\n",
      "Precision: 0.9744\n",
      "Recall: 0.9730\n",
      "F1 Score: 0.9735\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       alert       0.86      0.93      0.89        58\n",
      "      drowsy       0.99      0.98      0.98       424\n",
      "\n",
      "    accuracy                           0.97       482\n",
      "   macro avg       0.92      0.95      0.94       482\n",
      "weighted avg       0.97      0.97      0.97       482\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Generate and print classification report\n",
    "print(\"Classification Report:\\n\", classification_report(all_labels, all_preds, target_names=['alert', 'drowsy']))\n",
    "\n",
    "# Plot confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['alert', 'drowsy'], \n",
    "            yticklabels=['alert', 'drowsy'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
